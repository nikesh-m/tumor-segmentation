{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Reloading\n",
    "\n",
    "Goal of this notebook is to double check that I can load Keras model and Keras model checkpoint. Ultimately want to continue training on model on 2020 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras, glob, re, os, math\n",
    "import numpy as np\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.losses import mse\n",
    "from keras.layers import Conv3D, Activation, Add, UpSampling3D, Lambda, Dense\n",
    "from keras.layers import Input, Reshape, Flatten, Dropout, SpatialDropout3D\n",
    "from keras.optimizers import Adam as adam\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append('../auto_encoder/')\n",
    "from train_model import preprocess, read_img, preprocess_label\n",
    "from model import build_model  # For creating the model\n",
    "\n",
    "import SimpleITK as sitk  # For loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[-3,-2,-1])\n",
    "    dn = K.sum(K.square(y_true) + K.square(y_pred), axis=[-3,-2,-1]) + 1e-8\n",
    "    return K.mean(2 * intersection / dn, axis=[0,1])\n",
    "\n",
    "\n",
    "def loss_gt(e=1e-8):\n",
    "    \"\"\"\n",
    "    loss_gt(e=1e-8)\n",
    "    ------------------------------------------------------\n",
    "    Since keras does not allow custom loss functions to have arguments\n",
    "    other than the true and predicted labels, this function acts as a wrapper\n",
    "    that allows us to implement the custom loss used in the paper. This function\n",
    "    only calculates - L<dice> term of the following equation. (i.e. GT Decoder part loss)\n",
    "\n",
    "    L = - L<dice> + weight_L2 ∗ L<L2> + weight_KL ∗ L<KL>\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    `e`: Float, optional\n",
    "        A small epsilon term to add in the denominator to avoid dividing by\n",
    "        zero and possible gradient explosion.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss_gt_(y_true, y_pred): A custom keras loss function\n",
    "        This function takes as input the predicted and ground labels, uses them\n",
    "        to calculate the dice loss.\n",
    "\n",
    "    \"\"\"\n",
    "    def loss_gt_(y_true, y_pred):\n",
    "        y_true_float = Lambda(lambda x: K.cast(x, 'float32'), name='change_to_float')(y_true)\n",
    "\n",
    "        intersection = K.sum(K.abs(y_true_float * y_pred), axis=[-3,-2,-1])\n",
    "        dn = K.sum(K.square(y_true_float) + K.square(y_pred), axis=[-3,-2,-1]) + e\n",
    "\n",
    "        return - K.mean(2 * intersection / dn, axis=[0,1])\n",
    "\n",
    "    return loss_gt_\n",
    "\n",
    "# def loss_gt_(y_true, y_pred, e=1e-8):\n",
    "#     y_true_float = Lambda(lambda x: K.cast(x, 'float32'), name='change_to_float')(y_true)\n",
    "\n",
    "#     intersection = K.sum(K.abs(y_true_float * y_pred), axis=[-3,-2,-1])\n",
    "#     dn = K.sum(K.square(y_true_float) + K.square(y_pred), axis=[-3,-2,-1]) + e\n",
    "\n",
    "#     return - K.mean(2 * intersection / dn, axis=[0,1])\n",
    "\n",
    "# return loss_gt_\n",
    "\n",
    "def loss_VAE(input_shape, z_mean, z_var, weight_L2=0.1, weight_KL=0.1):\n",
    "    \"\"\"\n",
    "    loss_VAE(input_shape, z_mean, z_var, weight_L2=0.1, weight_KL=0.1)\n",
    "    ------------------------------------------------------\n",
    "    Since keras does not allow custom loss functions to have arguments\n",
    "    other than the true and predicted labels, this function acts as a wrapper\n",
    "    that allows us to implement the custom loss used in the paper. This function\n",
    "    calculates the following equation, except for -L<dice> term. (i.e. VAE decoder part loss)\n",
    "\n",
    "    L = - L<dice> + weight_L2 ∗ L<L2> + weight_KL ∗ L<KL>\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "     `input_shape`: A 4-tuple, required\n",
    "        The shape of an image as the tuple (c, H, W, D), where c is\n",
    "        the no. of channels; H, W and D is the height, width and depth of the\n",
    "        input image, respectively.\n",
    "    `z_mean`: An keras.layers.Layer instance, required\n",
    "        The vector representing values of mean for the learned distribution\n",
    "        in the VAE part. Used internally.\n",
    "    `z_var`: An keras.layers.Layer instance, required\n",
    "        The vector representing values of variance for the learned distribution\n",
    "        in the VAE part. Used internally.\n",
    "    `weight_L2`: A real number, optional\n",
    "        The weight to be given to the L2 loss term in the loss function. Adjust to get best\n",
    "        results for your task. Defaults to 0.1.\n",
    "    `weight_KL`: A real number, optional\n",
    "        The weight to be given to the KL loss term in the loss function. Adjust to get best\n",
    "        results for your task. Defaults to 0.1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss_VAE_(y_true, y_pred): A custom keras loss function\n",
    "        This function takes as input the predicted and ground labels, uses them\n",
    "        to calculate the L2 and KL loss.\n",
    "\n",
    "    \"\"\"\n",
    "    def loss_VAE_(y_true, y_pred):\n",
    "        c, H, W, D = input_shape\n",
    "        n = c * H * W * D\n",
    "\n",
    "        loss_L2 = K.mean(K.square(y_true - y_pred), axis=(1, 2, 3, 4)) # original axis value is (1,2,3,4).\n",
    "\n",
    "        loss_KL = (1 / n) * K.sum(\n",
    "            K.exp(z_var) + K.square(z_mean) - 1. - z_var,\n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "        return weight_L2 * loss_L2 + weight_KL * loss_KL\n",
    "\n",
    "    return loss_VAE_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venvs/.env_ae2/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:1045: UserWarning: model is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  , UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# path = '/home/ubuntu/model_ae_400_2020-11-03-0700/'\n",
    "path = '/home/ubuntu/model_ae_3_2020-11-03-0635/'\n",
    "\n",
    "model = keras.models.load_model(path,custom_objects={'dice_coefficient':dice_coefficient,'loss_gt_':loss_gt, 'loss_VAE_':loss_VAE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (4, 80, 96, 64)\n",
    "\n",
    "model2 = build_model(input_shape=input_shape, output_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoints = '/home/ubuntu/checkpoints/ae_weights.400-0.00843.hdf5'\n",
    "model2.load_weights(path_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [=====                   ](20 %)"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "# Get a list of files for all modalities individually\n",
    "end_index = 10\n",
    "input_shape = (4, 80, 96, 64)\n",
    "output_channels = 3\n",
    "\n",
    "data = np.empty((len(data_paths[:end_index]),) + input_shape, dtype=np.float32) \n",
    "labels = np.empty((len(data_paths[:end_index]), output_channels) + input_shape[1:], dtype=np.uint8)\n",
    "\n",
    "path = '/home/ubuntu/data/brats-data/MICCAI_BraTS_2018_Data_Training/'\n",
    "t1 = glob.glob(os.path.join(path, '*GG/*/*t1.nii.gz'))\n",
    "t2 = glob.glob(os.path.join(path, '*GG/*/*t2.nii.gz'))\n",
    "flair = glob.glob(os.path.join(path, '*GG/*/*flair.nii.gz'))\n",
    "t1ce = glob.glob(os.path.join(path, '*GG/*/*t1ce.nii.gz'))\n",
    "seg = glob.glob(os.path.join(path, '*GG/*/*seg.nii.gz'))  # Ground Truth\n",
    "\n",
    "pat = re.compile('.*_(\\w*)\\.nii\\.gz')\n",
    "\n",
    "data_paths = [{\n",
    "    pat.findall(item)[0]: item\n",
    "    for item in items\n",
    "}\n",
    "    for items in list(zip(t1, t2, t1ce, flair, seg))]\n",
    "\n",
    "total = len(data_paths[:end_index])\n",
    "step = 25 / total\n",
    "\n",
    "for i, imgs in enumerate(data_paths[:2]):\n",
    "    data[i] = np.array([preprocess(read_img(imgs[m]), input_shape[1:]) for m in ['t1', 't2', 't1ce', 'flair']],\n",
    "                       dtype=np.float32)\n",
    "    labels[i] = preprocess_label(read_img(imgs['seg']), input_shape[1:])[None, ...]\n",
    "\n",
    "    if ~np.isfinite(data[i]).any() or ~np.isfinite(labels[i]).any():\n",
    "        print('bad frame found:')\n",
    "        print(data_paths[i])\n",
    "        bad_frames.append(i)\n",
    "\n",
    "    # Print the progress bar\n",
    "    print('\\r' + f'Progress: '\n",
    "                 f\"[{'=' * int((i + 1) * step) + ' ' * (24 - int((i + 1) * step))}]\"\n",
    "                 f\"({math.ceil((i + 1) * 100 / (total))} %)\",\n",
    "          end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4, 80, 96, 64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model2.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 96, 64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  73, 115, 166, 190, 204, 205], dtype=uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels[:,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 80, 96, 64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0,:,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4, 80, 96, 64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 80, 96, 64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 80, 96, 64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
